{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFWTtZiqDCN3",
    "outputId": "0b72d566-d03a-48e9-9a18-76503a64dadf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "### Run this cell if running script in Google Colaboratory\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAUHZ96qqnj2"
   },
   "outputs": [],
   "source": [
    "### NOTE: If running script on operating system for first time, \n",
    "### run this cell.\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8hQpewiCmUX",
    "outputId": "6c6da12e-d165-465c-a328-74fbf523341d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Monthly Precipitation (in/mo.): 1.38842368\n",
      "Max Monthly Precipitation (in): 4.015114228\n",
      "Cumulative Precip. (in): 61.03\n",
      "Basin Area (mi²): 18490.92357\n",
      "Avg. Basin Lat. (°): 38.125316\n",
      "Basin Relief (ft): 10738.45645\n",
      "Channel Slope: 0.005081554\n",
      "Curve Number: 77.375\n",
      "Total Upstream Normal Storage (acre-ft): 986009.4\n",
      "Total Upstream Dam Height (ft): 3904.7\n",
      "Hydraulic Length (ft): 2113223.08\n",
      "Initial Capacity (acre-ft): 703001.86\n",
      "*****************************************************\n",
      "Predicted Capacity Loss Value (acre-ft):  20817.947\n"
     ]
    }
   ],
   "source": [
    "### Required libraries for script\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model  ### This library requires tensorflow to be installed on your OS (automatically installed in Google Colaboratory).\n",
    "import os\n",
    "\n",
    "\n",
    "#### Values for transformation and unstransformation of input and output data ####\n",
    "\n",
    "raw_min_x = [0.630073205118252,1.43810276557797,2.96269241947579,1.76472729118331, \n",
    "           3.44590962334884,5.1375514408174,0.000338858580945619,4.00369019395397,\n",
    "           0,0,10.0148352591427,6.62936325343745]\n",
    "\n",
    "raw_max_x = [1.83601494659418,3.73669154870064,7.87105554302205,12.5367912114883,\n",
    "           3.91209676270801,9.52841555145308,0.0989619485186843,4.53259949315326,\n",
    "           18.5541124009785,12.0109345668791,16.3542110492893,17.2997495062243]\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##### Defined functions for data transformation and scaling #####\n",
    "\n",
    "def transform(value):  \n",
    "  \"\"\" transforms the value or data provided to a natural logarithmic form \"\"\"\n",
    "  variables = []\n",
    "  for vals in value:\n",
    "    trans = np.sign(vals)*(np.log(abs(vals)+1))\n",
    "    variables.append(trans)\n",
    "  return variables\n",
    "\n",
    "def minmax_norm(value, raw_min, raw_max):\n",
    "  \"\"\" applies the linear min-max normalization \"\"\"\n",
    "  variables = []\n",
    "  for i in range(0,len(raw_min)):\n",
    "    norm = (0.7 * ((value[i]-raw_min[i])/(raw_max[i]-raw_min[i]))) + 0.15\n",
    "    variables.append(norm)\n",
    "  return variables \n",
    "\n",
    "def untransform_cap_loss(value):\n",
    "  \"\"\" untransforms the value or data provided to its original form \"\"\"\n",
    "  untrans = np.exp(((value-0.15)/0.7)*(14.1042777914158-0.693147180559945)+0.693147180559945)-1  \n",
    "  return untrans\n",
    "\n",
    "###################################################################\n",
    "\n",
    "\n",
    "### Loading Model --------  On line below, be sure to change and set the 'path' in load_model('path') for the file path of the 'calibrated_best_model.hdf5' file on your OS or Google Drive\n",
    "model = load_model('path')\n",
    "\n",
    "\n",
    "\n",
    "### Input Values ###\n",
    "\n",
    "mean_mnth_precip = float(input('Mean Monthly Precipitation (in/mo.): ')) \n",
    "max_mnth_precip = float(input('Max Monthly Precipitation (in): '))\n",
    "cumulative_precip = float(input('Cumulative Precip. (in): ')) \n",
    "basin_area = float(input('Basin Area (mi\\N{SUPERSCRIPT TWO}): '))\n",
    "avg_basin_lat = float(input('Avg. Basin Lat. (°): '))\n",
    "basin_rlf = float(input('Basin Relief (ft): '))   \n",
    "channel_slp = float(input('Channel Slope: '))    \n",
    "curve_number = float(input('Curve Number: '))  \n",
    "tot_upstr_nrm_str = float(input('Total Upstream Normal Storage (acre-ft): ')) \n",
    "tot_upstrm_dam_ht = float(input('Total Upstream Dam Height (ft): ')) \n",
    "hydraulic_len = float(input('Hydraulic Length (ft): '))     \n",
    "initial_capacity =  float(input('Initial Capacity (acre-ft): '))     \n",
    "\n",
    "#####################\n",
    "\n",
    "\n",
    "#Create list of input variables in specified order --- NOTE: Do not change order. Order of variables important for accurate model performance.\n",
    "predictor_variables = [mean_mnth_precip, max_mnth_precip, cumulative_precip, basin_area,  \n",
    "                       avg_basin_lat,basin_rlf, channel_slp, curve_number, tot_upstr_nrm_str,\n",
    "                       tot_upstrm_dam_ht, hydraulic_len, initial_capacity]\n",
    "\n",
    "ls_values = minmax_norm(transform(predictor_variables),raw_min_x,raw_max_x)  #log transformation and minmax scaling of input values\n",
    "ls_array = np.array(ls_values).reshape(1,-1)  #create numpy array of input values for prediction \n",
    "prediction = model.predict(ls_array)  #performs prediction based on input values\n",
    "predicted_value = untransform_cap_loss(prediction)  #untransforms the resulting predicted value\n",
    "print('*'*53)\n",
    "print('Predicted Capacity Loss Value (acre-ft): ', predicted_value[0][0])  #displays predicted result"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RSI_Capacity_Loss_Predictor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
